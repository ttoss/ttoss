---
title: AI
slug: /ai
---

# Artificial Intelligence at ttoss

This section explains how product teams at ttoss integrate AI tools to accelerate learning, improve decisions, and ship higher-value features faster. We focus on practical integration points across discovery, design, engineering, and release workflows so AI becomes an amplifying capability—not a distraction.

## What You'll Find Here

**[Agentic Development Principles](/docs/ai/agentic-development-principles)** - The foundational laws governing AI integration in product development. These principles define the immutable constraints and economic forces that shape how AI tools succeed or fail in real workflows. Essential reading for understanding _why_ certain AI integration patterns work while others create chaos.

**[Agentic Design Patterns](/docs/ai/agentic-design-patterns)** - Reusable engineering solutions that implement the principles in production code. These patterns solve recurring problems of cost, latency, reliability, and risk. Use these to bridge abstract principles and working systems.

**[Prompt Engineering](/docs/ai/prompt-engineering)** - Practical guidance for communicating effectively with AI agents. Learn the anti-patterns that guarantee failure and the techniques that produce reliable results. Focuses on structured prompting, context management, and reducing hallucination.

## Core Philosophy

AI integration at ttoss follows [The Principle of Quantified Overall Economics](/docs/product/product-development/principles#e1-the-principle-of-quantified-overall-economics-select-actions-based-on-quantified-overall-economic-impact). Every AI tool and workflow must demonstrate measurable value—reduced cycle time, improved quality, or faster learning—not just novelty.

We build on principles from [The Principles of Product Development Flow](/docs/product/product-development/principles) to ensure AI accelerates feedback loops ([B3: The Batch Size Feedback Principle](/docs/product/product-development/principles#b3-the-batch-size-feedback-principle-reducing-batch-sizes-accelerates-feedback)), preserves developer flow ([FF8: The Fast-Learning Principle](/docs/product/product-development/principles#ff8-the-fast-learning-principle-use-fast-feedback-to-make-learning-faster-and-more-efficient)), and reduces variability in outcomes.

## What This is Not

This documentation does **not** cover:

- **Model Training**: We don't address fine-tuning, retraining workflows, or dataset engineering.
- **Model Architecture**: No deep dives into transformers, attention mechanisms, or research papers.
- **Infrastructure**: GPU clusters, hardware optimization, and low-level performance tuning are out of scope.

We focus exclusively on _using_ AI as a development tool, not building AI systems.
